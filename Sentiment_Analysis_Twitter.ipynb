{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoSWXH5AR-ur"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zkar9bMxTR2Q"
   },
   "outputs": [],
   "source": [
    "data_path = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "MbLkQDz0UUg2",
    "outputId": "02ecc1e3-abf1-48a3-88e8-424f5dc84a86"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path, encoding = \"ISO-8859-1\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gieaEeVXUZcw",
    "outputId": "41eb1f2f-7567-4ff7-b09c-19bc09532511"
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk1BsM3IWXRg"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRw-OYHOUr0T"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SMSDFFPUcNc"
   },
   "outputs": [],
   "source": [
    "def Preprocessing(text):\n",
    "    # stripping quotes at end of text\n",
    "    text=text.strip('')\n",
    "\n",
    "    # removing twitter handles @user\n",
    "    text=re.sub(\"@[\\w]*\",\" \",text)\n",
    "\n",
    "    # removing URLs with the space\n",
    "    text = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' ', text)\n",
    "\n",
    "    # stripping space, \" and ' from text\n",
    "    text = text.strip(' \"\\'')\n",
    "\n",
    "    # removing repeated letters of string such as yessss to yes \n",
    "    text=re.sub(r'(.)\\1{3,}', r'\\1', text)\n",
    "\n",
    "    # removing the special characters\n",
    "    text = re.sub('[^A-Za-z]', ' ', text)\n",
    "\n",
    "    # replacing two or more dots with space\n",
    "    text = re.sub(\"\\\\.{2,}\",\" \",text)\n",
    "\n",
    "    # converting all text into small letters and storing them as words for further processing\n",
    "    text_list = text.lower().split()\n",
    "\n",
    "    # stemming the words (removing prefix and postfix) using Porter Stemming algorithm..\n",
    "    text_list = [ps.stem(word) for word in text_list]\n",
    "    \n",
    "    return ' '.join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4o7LqGpWV8rz"
   },
   "outputs": [],
   "source": [
    "data['Preprocessed_data']=data['SentimentText'].apply(Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "b8ENuu9xWEeH",
    "outputId": "c3dce0db-8a64-41fb-afbf-f6b15b91efc5"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xLblBgQWbE9"
   },
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7UHiV6uWKUg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnPhRcqqYG_z",
    "outputId": "22af8ba0-a518-4c13-f56d-2b5fd6fd6ca3"
   },
   "outputs": [],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nWe966YYfdK"
   },
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ne_LAW3QW0L3"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "count_vectorization = CountVectorizer()\n",
    "tfidf_transformation = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2xRFu2vZOzC"
   },
   "outputs": [],
   "source": [
    "X_train_count_vector = count_vectorization.fit_transform(train[\"Preprocessed_data\"])\n",
    "X_train_tfidf_vector = tfidf_transformation.fit_transform(X_train_count_vector)\n",
    "\n",
    "X_test_count_vector = count_vectorization.transform(test[\"Preprocessed_data\"])\n",
    "X_test_tfidf_vector = tfidf_transformation.transform(X_test_count_vector)\n",
    "\n",
    "y_train = train['Sentiment']\n",
    "y_test = test['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zl3JuNkCZ6Em"
   },
   "outputs": [],
   "source": [
    "print(train[\"Preprocessed_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlpK5rATaq_p"
   },
   "source": [
    "# Training and Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0CAXht0auHE"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLnB7sAbI9Ng"
   },
   "outputs": [],
   "source": [
    "model_prediction = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMtZUCxhaw03"
   },
   "outputs": [],
   "source": [
    "# SVM - Stochastic Gradient Descent\n",
    "model = SGDClassifier(max_iter=1000, tol=1e-3, loss=\"modified_huber\").fit(X_train_tfidf_vector, y_train)\n",
    "model_prediction['SVM-SGD'] = model.predict(X_test_tfidf_vector)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "model = MultinomialNB().fit(X_train_tfidf_vector, y_train)\n",
    "model_prediction['Multinomial'] = model.predict(X_test_tfidf_vector)\n",
    "\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "model = BernoulliNB().fit(X_train_tfidf_vector, y_train)\n",
    "model_prediction['Bernoulli'] = model.predict(X_test_tfidf_vector)\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(C=1).fit(X_train_tfidf_vector, y_train)\n",
    "model_prediction['Logistic'] = model.predict(X_test_tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SVM - Support Vector Classifier\n",
    "# model = SVC(gamma='auto', C=1).fit(X_train_tfidf_vector, y_train)\n",
    "# model_prediction['SVM'] = model.predict(X_test_tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "model = DecisionTreeClassifier().fit(X_train_tfidf_vector, y_train)\n",
    "model_prediction['Decision Tree'] = model.predict(X_test_tfidf_vector)\n",
    "\n",
    "\n",
    "# Votting LR-SGD\n",
    "clf1 = LogisticRegression(C=1)\n",
    "clf2 = SGDClassifier(max_iter=1000, tol=1e-3, loss=\"modified_huber\")\n",
    "model = VotingClassifier(estimators=[('LR', clf1),('SGD', clf2)],voting='soft').fit(X_train_tfidf_vector, y_train)\n",
    "model_prediction['Votting-LR-SGD'] = model.predict(X_test_tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMY8KwbKXKk_"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "az-WWFgZXB_c",
    "outputId": "fad7fc62-0d24-41a3-adfa-6a8842bb2186"
   },
   "outputs": [],
   "source": [
    "print(\"ACCURACY SCORE:\\n\")\n",
    "for model_name in model_prediction.keys():\n",
    "  print(model_name, ': ', round(accuracy_score(y_test, model_prediction[model_name])*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AM-XCENX-0I",
    "outputId": "e3ce0e50-cd28-4df8-961e-fa11154a0738"
   },
   "outputs": [],
   "source": [
    "print(\"F1 SCORE:\\n\")\n",
    "for model_name in model_prediction.keys():\n",
    "  print(model_name, ': ', round(f1_score(y_test, model_prediction[model_name]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "for model_name in model_prediction.keys():\n",
    "        pred = precision_recall_fscore_support(y_test,model_prediction[model_name],average='macro')\n",
    "\n",
    "        print(f\"\\n{model_name}|{' '*(17- len(model_name))}   precision         recall          Fscore\")\n",
    "        print('                      ',round(pred[0]*100,2), end= '             ')\n",
    "        print(round(pred[1]*100,2), end= '           ')\n",
    "        print(round(pred[2]*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrpdNZQBzQOU"
   },
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "YCNipcgrg0XM",
    "outputId": "cd4c3c42-155d-4ad3-af94-c8f6d95b42d3"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for Logistic Regression\n",
    "import seaborn as sns\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, model_prediction['Logistic'])\n",
    "axes = [\"Negative\", \"Positive\"]\n",
    "confusion_matrix_df = pd.DataFrame(conf_mat, axes, axes, dtype=int)\n",
    "sns.heatmap(confusion_matrix_df, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confustion Matrix for Logistic Regression\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sentiment Analysis - Twitter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
